这两个文件想法如下：

神经网络一般最后一层只是线性层，因此可以看成是基函数的组合，所以从某种意义上神经网络的优势在于可以任意地选择基函数，或者说神经网络的形式可以很顺利地调整基函数，使基函数不同于有限元中的限定形式。

这样，一个很自然的想法如下：

用一个网络拟合基函数，另一个网络用于生成测试函数，然后计算最优的基函数的线性组合（这里的最优组合系数通过解一个线性方程组得到）（或许有其他计算最优基函数的方法），将残差作为损失函数优化第一个网络，用残差的相反数优化第二个网络。

现在的问题如下：

1.训练非常慢，经过测试发现计算损失花时较多，反向传播更是花费大量时间。

2.损失表现非常不稳定的行为，并且不是稳步下降。